{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.datasets import boston_housing\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import regularizers  # 正则化\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score\n",
    "import seaborn as sns\n",
    "#import  os\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models,layers, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Annual_Pre</th>\n",
       "      <th>srad_02</th>\n",
       "      <th>srad_08</th>\n",
       "      <th>srad_09</th>\n",
       "      <th>srad_10</th>\n",
       "      <th>srad_11</th>\n",
       "      <th>srad_12</th>\n",
       "      <th>mean_srad</th>\n",
       "      <th>wind_11</th>\n",
       "      <th>water_vapo</th>\n",
       "      <th>...</th>\n",
       "      <th>NIR_8</th>\n",
       "      <th>RED_9</th>\n",
       "      <th>SWIR_7</th>\n",
       "      <th>SWIR_9</th>\n",
       "      <th>Iron_oxide_7</th>\n",
       "      <th>Iron_oxide_8</th>\n",
       "      <th>Iron_oxide_9</th>\n",
       "      <th>Ipvi_8</th>\n",
       "      <th>Ipvi_9</th>\n",
       "      <th>OC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1012</td>\n",
       "      <td>7986</td>\n",
       "      <td>20021</td>\n",
       "      <td>14696</td>\n",
       "      <td>9206</td>\n",
       "      <td>5534</td>\n",
       "      <td>4069</td>\n",
       "      <td>13342.75000</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3115</td>\n",
       "      <td>0.0525</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>0.1795</td>\n",
       "      <td>2.076923</td>\n",
       "      <td>2.344828</td>\n",
       "      <td>2.560976</td>\n",
       "      <td>0.820817</td>\n",
       "      <td>0.846715</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>900</td>\n",
       "      <td>6272</td>\n",
       "      <td>17702</td>\n",
       "      <td>13251</td>\n",
       "      <td>7747</td>\n",
       "      <td>4101</td>\n",
       "      <td>2867</td>\n",
       "      <td>11755.75000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.985833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2785</td>\n",
       "      <td>0.0790</td>\n",
       "      <td>0.2740</td>\n",
       "      <td>0.2420</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>2.522523</td>\n",
       "      <td>2.289855</td>\n",
       "      <td>0.665472</td>\n",
       "      <td>0.799492</td>\n",
       "      <td>24.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>664</td>\n",
       "      <td>11554</td>\n",
       "      <td>25105</td>\n",
       "      <td>19045</td>\n",
       "      <td>13175</td>\n",
       "      <td>9175</td>\n",
       "      <td>7290</td>\n",
       "      <td>17209.25000</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.075830</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2785</td>\n",
       "      <td>0.1380</td>\n",
       "      <td>0.3440</td>\n",
       "      <td>0.3155</td>\n",
       "      <td>2.550847</td>\n",
       "      <td>2.672131</td>\n",
       "      <td>2.379310</td>\n",
       "      <td>0.630804</td>\n",
       "      <td>0.633466</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>591</td>\n",
       "      <td>8811</td>\n",
       "      <td>20704</td>\n",
       "      <td>15389</td>\n",
       "      <td>9983</td>\n",
       "      <td>6326</td>\n",
       "      <td>4860</td>\n",
       "      <td>14028.08333</td>\n",
       "      <td>5.2</td>\n",
       "      <td>1.242500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2945</td>\n",
       "      <td>0.1165</td>\n",
       "      <td>0.2800</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>1.885135</td>\n",
       "      <td>2.062500</td>\n",
       "      <td>2.080357</td>\n",
       "      <td>0.664786</td>\n",
       "      <td>0.683853</td>\n",
       "      <td>12.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>427</td>\n",
       "      <td>10064</td>\n",
       "      <td>23325</td>\n",
       "      <td>17136</td>\n",
       "      <td>11475</td>\n",
       "      <td>7714</td>\n",
       "      <td>5938</td>\n",
       "      <td>15587.66667</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3385</td>\n",
       "      <td>0.1820</td>\n",
       "      <td>0.3675</td>\n",
       "      <td>0.3560</td>\n",
       "      <td>2.692771</td>\n",
       "      <td>2.817647</td>\n",
       "      <td>3.008264</td>\n",
       "      <td>0.585640</td>\n",
       "      <td>0.579191</td>\n",
       "      <td>7.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Annual_Pre  srad_02  srad_08  srad_09  srad_10  srad_11  srad_12  \\\n",
       "0        1012     7986    20021    14696     9206     5534     4069   \n",
       "1         900     6272    17702    13251     7747     4101     2867   \n",
       "2         664    11554    25105    19045    13175     9175     7290   \n",
       "3         591     8811    20704    15389     9983     6326     4860   \n",
       "4         427    10064    23325    17136    11475     7714     5938   \n",
       "\n",
       "     mean_srad  wind_11  water_vapo  ...   NIR_8   RED_9  SWIR_7  SWIR_9  \\\n",
       "0  13342.75000      4.1    0.880000  ...  0.3115  0.0525  0.2100  0.1795   \n",
       "1  11755.75000      3.0    0.985833  ...  0.2785  0.0790  0.2740  0.2420   \n",
       "2  17209.25000      3.2    1.075830  ...  0.2785  0.1380  0.3440  0.3155   \n",
       "3  14028.08333      5.2    1.242500  ...  0.2945  0.1165  0.2800  0.2390   \n",
       "4  15587.66667      2.2    0.900000  ...  0.3385  0.1820  0.3675  0.3560   \n",
       "\n",
       "   Iron_oxide_7  Iron_oxide_8  Iron_oxide_9    Ipvi_8    Ipvi_9    OC  \n",
       "0      2.076923      2.344828      2.560976  0.820817  0.846715  34.7  \n",
       "1      2.250000      2.522523      2.289855  0.665472  0.799492  24.1  \n",
       "2      2.550847      2.672131      2.379310  0.630804  0.633466   8.7  \n",
       "3      1.885135      2.062500      2.080357  0.664786  0.683853  12.8  \n",
       "4      2.692771      2.817647      3.008264  0.585640  0.579191   7.8  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = pd.read_csv(\"train.csv\",encoding = 'UTF-8')\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set shape:\t (8716, 43)\n",
      "test set shape:\t\t (969, 43)\n"
     ]
    }
   ],
   "source": [
    "xs, ys = np.split(data2.values, [-1], axis=1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(xs,ys,test_size = 0.1, random_state = 1)\n",
    "print('training set shape:\\t', x_train.shape)\n",
    "print('test set shape:\\t\\t', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#构建神经网络模型\n",
    "def build_model():\n",
    "    #这里使用Sequential模型\n",
    "    model = models.Sequential()#初始化\n",
    "    #进行层的搭建，注意第二层往后没有输入形状(input_shape)，它可以自动推导出输入的形状等于上一层输出的形状\n",
    "    #unit=n:输出大小； \n",
    "    model.add(layers.Dense(30, activation='tanh',input_shape=(x_train.shape[1],)))\n",
    "    model.add(Dropout(0.2))  # 丢弃神经元链接概率\n",
    "    model.add(layers.Dense(30, \n",
    "#                            kernel_regularizer=regularizers.l2(0.01),  # 施加在权重上的正则项\n",
    "#                            activity_regularizer=regularizers.l1(0.01),  # 施加在输出上的正则项\n",
    "                           activation='tanh',\n",
    "#                            bias_regularizer=keras.regularizers.l1_l2(0.01)  # 施加在偏置向量上的正则项\n",
    "                          ))\n",
    "    #回归一般输出层用线性激活函数\n",
    "    \n",
    "    model.add(layers.Dense(1,activation='linear'))\n",
    "    #编译网络\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_(x_train,y_train, x_test,y_test,num_epochs = 100):\n",
    "    mean = x_train.mean(axis=0)\n",
    "    x_train -= mean\n",
    "    std = x_train.std(axis=0)\n",
    "    x_train /= std \n",
    "    x_test -= mean\n",
    "    x_test /= std\n",
    "    model = build_model()\n",
    "    print(model.summary())\n",
    "    #batch_size：每次用来梯度下降的批处理数据的大小，verbose：日志冗长度，int：冗长度，0：不输出训练过程，1：输出训练进度，2：输出每一个epoch\n",
    "    history = model.fit(x_train, y_train,epochs=num_epochs, batch_size=10, verbose=2, validation_data = (x_test, y_test))\n",
    "    predicts = model.predict(x_test)\n",
    "    for i in range(len(predicts)):\n",
    "        print(y_test[i],predicts[i])\n",
    "        pass\n",
    "    return predicts,history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
